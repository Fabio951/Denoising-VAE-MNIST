{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing lambda parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_lambda(lambdas):\n",
    "    data_root_dir = 'Dataset'\n",
    "    train_dataset, test_dataset = load_datasets(data_root_dir)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=True)\n",
    "    \n",
    "    \n",
    "    noise_try = [0, 0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2]\n",
    "    scale_try = [0, 0.01, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "    \n",
    "    num_epochs = 25\n",
    "    load_weights = False\n",
    "    load_best = True\n",
    "    \n",
    "    log_loss = []\n",
    "    log_noise = []\n",
    "    log_crop = []\n",
    "    for lambda_ in lambdas:\n",
    "        encoded_space_dim = 5\n",
    "        net = VAE(encoded_space_dim=encoded_space_dim, lambda_=lambda_)\n",
    "        \n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        optim = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        \n",
    "        device = torch.device(\"cuda\")\n",
    "        net.to(device)\n",
    "        \n",
    "        val_loss_log = []\n",
    "        for epoch in range(num_epochs):\n",
    "            if load_weights or (load_best and epoch>0.5):\n",
    "                print('Loaded!')\n",
    "                net.load_state_dict(torch.load('ckpt/net_params_%s.pth' %(str(lambda_*100))))\n",
    "            print('EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "            train_epoch(net, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optim, show_steps=20, \n",
    "                        use_noise=True)\n",
    "            val_loss = test_epoch(net, dataloader=test_dataloader, loss_fn=loss_fn)\n",
    "            val_loss_log.append(val_loss.item())\n",
    "            print('\\n\\n\\t VALIDATION - EPOCH %d/%d - loss: %f\\n\\n' % (epoch + 1, num_epochs, val_loss))\n",
    "            \n",
    "            #clear_output(wait = True)\n",
    "            #show_progress(0, test_dataset, net, epoch)\n",
    "            #plt.plot(range(1,epoch+2), val_loss_log)\n",
    "            \n",
    "            if (epoch<0.5 or val_loss.item()<min(val_loss_log[:-1])):\n",
    "                print('Saved!')\n",
    "                torch.save(net.state_dict(), 'ckpt/net_params_%s.pth' %(str(lambda_*100)))\n",
    "        log_loss.append(val_loss_log)\n",
    "        \n",
    "        net.load_state_dict(torch.load('ckpt/net_params_%s.pth' %(str(lambda_*100)), map_location='cpu'))\n",
    "        net.to('cpu')\n",
    "        \n",
    "        #show_result(net, test_dataset)\n",
    "        \n",
    "        loss_noise, loss_crop = test_noise_crop_opt(net, test_dataloader, loss_fn, noise_try, scale_try)\n",
    "        log_noise.append(loss_noise)\n",
    "        log_crop.append(loss_crop)\n",
    "        \n",
    "    #for i, log in enumerate(log_loss):\n",
    "    #    plt.plot(range(1, num_epochs+1), log, label=str(lambdas[i]))\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    #\n",
    "    #for i, log in enumerate(log_noise):\n",
    "    #    plt.plot(noise_try, log, label=str(lambdas[i]))\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    #\n",
    "    #for i, log in enumerate(log_crop):\n",
    "    #    plt.plot(scale_try, log, label=str(lambdas[i]))\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    \n",
    "    return log_loss, loss_noise, loss_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best dimension of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_hidden(hidden):\n",
    "    data_root_dir = 'Dataset'\n",
    "    train_dataset, test_dataset = load_datasets(data_root_dir)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=True)\n",
    "    \n",
    "    num_epochs = 25\n",
    "    load_weights = False\n",
    "    load_best = True\n",
    "    \n",
    "    log_loss = []\n",
    "    log_noise = []\n",
    "    log_crop = []\n",
    "    for hid in hidden:\n",
    "        encoded_space_dim = hid\n",
    "        lambda_ = 0.75\n",
    "        net = VAE(encoded_space_dim=encoded_space_dim, lambda_=lambda_)\n",
    "        \n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        optim = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        \n",
    "        device = torch.device(\"cuda\")\n",
    "        net.to(device)\n",
    "        \n",
    "        val_loss_log = []\n",
    "        for epoch in range(num_epochs):\n",
    "            if load_weights or (load_best and epoch>0.5):\n",
    "                print('Loaded!')\n",
    "                net.load_state_dict(torch.load('ckpt/net_params_%s.pth' %(str(hid))))\n",
    "            print('EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "            train_epoch(net, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optim, show_steps=20,\n",
    "                        use_noise=True)\n",
    "            val_loss = test_epoch(net, dataloader=test_dataloader, loss_fn=loss_fn)\n",
    "            val_loss_log.append(val_loss.item())\n",
    "            print('\\n\\n\\t VALIDATION - EPOCH %d/%d - loss: %f\\n\\n' % (epoch + 1, num_epochs, val_loss))\n",
    "            \n",
    "            #clear_output(wait = True)\n",
    "            #show_progress(0, test_dataset, net, epoch)\n",
    "            #plt.plot(range(1,epoch+2), val_loss_log)\n",
    "            \n",
    "            if (epoch<0.5 or val_loss.item()<min(val_loss_log[:-1])):\n",
    "                print('Saved!')\n",
    "                torch.save(net.state_dict(), 'ckpt/net_params_%s.pth' %(str(hid)))\n",
    "        log_loss.append(val_loss_log)\n",
    "        \n",
    "        net.load_state_dict(torch.load('ckpt/net_params_%s.pth' %(str(hid)), map_location='cpu'))\n",
    "        net.to('cpu')\n",
    "        \n",
    "        #show_result(net, test_dataset)\n",
    "        \n",
    "        noise_try = [0, 0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2]\n",
    "        scale_try = [0, 0.01, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "        loss_noise, loss_crop = test_noise_crop_opt(net, test_dataloader, loss_fn, noise_try, scale_try)\n",
    "        log_noise.append(loss_noise)\n",
    "        log_crop.append(loss_crop)\n",
    "        \n",
    "    return log_loss, log_noise, log_crop\n",
    "    #fig = plt.figure(figsize=(14,10))\n",
    "    #for i, log in enumerate(log_loss):\n",
    "    #    plt.plot(range(1, num_epochs+1), log, label=str(hidden[i]))\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    #\n",
    "    #return    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the performance for various levels of noise and crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_noise_crop_opt(net, dataloader, loss_fn, noise_try, scale_try):\n",
    "    net.eval()\n",
    "    device = torch.device('cpu')\n",
    "    net.to(device)\n",
    "    \n",
    "    #Noise\n",
    "    #limits_loss_noise = compute_limits_loss_noise(net, dataloader, loss_fn)\n",
    "    print('\\n@@@@@@@@@@@@@@@@@@@@@@@   Noise testing:\\n')\n",
    "    loss_log_noise = []\n",
    "    for noise_level in noise_try:\n",
    "        transform_noise = transforms.Lambda(lambda x: x + noise_level*torch.randn(x.shape))\n",
    "        with torch.no_grad():\n",
    "            conc_out = torch.Tensor().float()\n",
    "            conc_label = torch.Tensor().float()\n",
    "            for sample_batch in dataloader:\n",
    "                image_batch_or = sample_batch[0].clone()\n",
    "                image_batch = transform_noise(sample_batch[0])\n",
    "                out = net(image_batch)\n",
    "                conc_out = torch.cat([conc_out, out.cpu()])\n",
    "                conc_label = torch.cat([conc_label, image_batch_or.cpu()])\n",
    "            val_loss = loss_fn(conc_out, conc_label)#-limits_loss_noise[0]\n",
    "            #val_loss *= 100/(limits_loss_noise[1]-limits_loss_noise[0])\n",
    "            loss_log_noise.append(val_loss.item())\n",
    "            print('Test loss with a %.1f %% noise level: %.4f' %(noise_level*100, val_loss))\n",
    "            #fig, axs = plt.subplots(5,3 , figsize=(3,5))\n",
    "            #for index in range(5):\n",
    "            #    img = image_batch[index].view(1,-1,28,28)\n",
    "            #    rec_img  = net(img)\n",
    "            #    axs[index, 0].imshow(image_batch_or[index].cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "            #    axs[index,0].axis('off')\n",
    "            #    axs[index, 1].imshow(image_batch[index].cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "            #    axs[index,1].axis('off')\n",
    "            #    axs[index, 2].imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "            #    axs[index,2].axis('off')\n",
    "            #plt.tight_layout()\n",
    "            #plt.show()\n",
    "            #plt.plot\n",
    "    #plt.plot(noise_try, loss_log_noise)\n",
    "    #plt.show()\n",
    "        \n",
    "    #Crop\n",
    "    #limits_loss_crop = compute_limits_loss_crop(net, dataloader, loss_fn)\n",
    "    print('\\n@@@@@@@@@@@@@@@@@@@@@@@   Crop testing:\\n')\n",
    "    loss_log_crop = []\n",
    "    for scale in scale_try:\n",
    "        transform_crop = transforms.RandomErasing(p=1, scale=(scale,scale), ratio=(0.5,2))\n",
    "        with torch.no_grad():\n",
    "            conc_out = torch.Tensor().float()\n",
    "            conc_label = torch.Tensor().float()\n",
    "            for sample_batch in dataloader:\n",
    "                image_batch_or = sample_batch[0].clone()\n",
    "                image_batch = sample_batch[0]\n",
    "                if scale!=0:\n",
    "                    for i in range(len(image_batch)):\n",
    "                        image_batch[i] = transform_crop(image_batch[i])\n",
    "                out = net(image_batch)\n",
    "                conc_out = torch.cat([conc_out, out.cpu()])\n",
    "                conc_label = torch.cat([conc_label, image_batch_or.cpu()])\n",
    "            val_loss = loss_fn(conc_out, conc_label)#-limits_loss_crop[0]\n",
    "            #val_loss *= 100/(limits_loss_crop[1]-limits_loss_crop[0])\n",
    "            loss_log_crop.append(val_loss.item())\n",
    "            print('Test loss with a %.1f %% crop: %.4f' %(scale*100, val_loss))\n",
    "            #fig, axs = plt.subplots(5, 3, figsize=(3,5))\n",
    "            #for index in range(5):\n",
    "            #    img = image_batch[index].view(1,-1,28,28)\n",
    "            #    rec_img  = net(img)\n",
    "            #    axs[index, 0].imshow(image_batch_or[index].cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "            #    axs[index,0].axis('off')\n",
    "            #    axs[index, 1].imshow(image_batch[index].cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "            #    axs[index,1].axis('off')\n",
    "            #    axs[index, 2].imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "            #    axs[index,2].axis('off')\n",
    "            #plt.tight_layout()\n",
    "            #plt.show()\n",
    "    #plt.plot(scale_try, loss_log_crop)\n",
    "    #plt.show()\n",
    "    return loss_log_noise, loss_log_crop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
